{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzBSjzzQAuZ8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classification of the three tasks with the Augmented Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6SlC8pp9QzB2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\utente\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def get_classifiers(names, multilabel=False):\n",
    "    if 'random' in names or 'majority' in names:\n",
    "        return names\n",
    "\n",
    "    if multilabel:\n",
    "        linear_classifier = OneVsRestClassifier(LinearSVC())\n",
    "        rf_classifier = OneVsRestClassifier(RandomForestClassifier())\n",
    "        nb_classifier = OneVsRestClassifier(GaussianNB())\n",
    "        kn_classifier = OneVsRestClassifier(KNeighborsClassifier())\n",
    "        svc_classifier = OneVsRestClassifier(SVC(kernel='poly'))\n",
    "    else:\n",
    "        linear_classifier = LinearSVC()\n",
    "        rf_classifier = RandomForestClassifier()\n",
    "        nb_classifier = GaussianNB()\n",
    "        kn_classifier = KNeighborsClassifier()\n",
    "        svc_classifier = SVC(kernel='poly')\n",
    "\n",
    "    classifiers = []\n",
    "    if 'linearsvc' in names:\n",
    "        classifiers.append(linear_classifier)\n",
    "    if 'randomforest' in names:\n",
    "        classifiers.append(rf_classifier)\n",
    "    if 'gaussiannb' in names:\n",
    "        classifiers.append(nb_classifier)\n",
    "    if 'kneighbors' in names:\n",
    "        classifiers.append(kn_classifier)\n",
    "    if 'svc' in names:\n",
    "        classifiers.append(svc_classifier)\n",
    "    return classifiers\n",
    "\n",
    "\n",
    "def get_embeddings(corpus, embedding):  # embedding in [tfidf, sbert, legalbert]\n",
    "    if embedding == \"sbert\":\n",
    "        model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "        sentence_embeddings = model.encode(corpus)\n",
    "    elif embedding == \"legalbert\":\n",
    "        model = SentenceTransformer(\"nlpaueb/legal-bert-small-uncased\")\n",
    "        sentence_embeddings = model.encode(corpus)\n",
    "    elif embedding == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        sentence_embeddings = vectorizer.fit_transform(corpus)\n",
    "        sentence_embeddings = sentence_embeddings.toarray()\n",
    "        return sentence_embeddings\n",
    "    else:\n",
    "        print(\"wrong embedding name\")\n",
    "        return\n",
    "    return sentence_embeddings\n",
    "\n",
    "\n",
    "def argument_classification(df, classifiers, embeddings):\n",
    "    corpus = df['Text'].values\n",
    "    random.seed(42)\n",
    "    for embedding in embeddings:\n",
    "        X = get_embeddings(corpus, embedding)\n",
    "\n",
    "        for classifier in get_classifiers(classifiers):\n",
    "            y_pred_all = None\n",
    "            y_test_all = None\n",
    "            for fold in range(1, 6):\n",
    "                X_train = X[df['Split'] != fold]\n",
    "                X_test = X[df['Split'] == fold]\n",
    "\n",
    "                y_train = df[df['Split'] != fold]['Name']\n",
    "                y_test = df[df['Split'] == fold]['Name']\n",
    "\n",
    "                if classifier == 'random':\n",
    "                    labs = list(set(y_train))\n",
    "                    y_pred = [random.choice(labs) for _ in range(len(X_test))]\n",
    "                elif classifier == 'majority':\n",
    "                    labs = set(y_train)\n",
    "                    maj = 0\n",
    "                    for l in labs:\n",
    "                        val = list(y_train).count(l)\n",
    "                        if val > maj:\n",
    "                            majority_class = l\n",
    "                            maj = val\n",
    "                    y_pred = [majority_class for _ in range(len(X_test))]\n",
    "                else:\n",
    "                    classifier.fit(X_train, y_train)\n",
    "                    y_pred = classifier.predict(X_test)\n",
    "\n",
    "                y_pred_all = y_pred if y_pred_all is None else np.concatenate([y_pred_all, y_pred])\n",
    "                y_test_all = y_test if y_test_all is None else np.concatenate([y_test_all, y_test])\n",
    "\n",
    "            labels = sorted(set(y_train))\n",
    "\n",
    "            report = classification_report(y_test_all, y_pred_all, target_names=labels)\n",
    "            print(\"EMBEDDING:\" + embedding + \"      CLASSIFIER:\" + str(classifier.__class__).split('.')[-1].split(\"'\")[0])\n",
    "            print(report)\n",
    "            print(\"=\"*40)\n",
    "\n",
    "\n",
    "def attribute_classification(df, classifiers, embeddings, attribute):\n",
    "    df = df.dropna(subset=[attribute])\n",
    "\n",
    "    df[attribute] = df[attribute].apply(lambda x: [x] if not isinstance(x, list) else x)\n",
    "\n",
    "    df[attribute] = df[attribute].apply(lambda x: sorted(list(set(x))) if x != [] else np.NaN)\n",
    "\n",
    "    df = df.dropna(subset=[attribute])\n",
    "    print(df[attribute].value_counts(),len(df))\n",
    "\n",
    "\n",
    "    corpus = df['Text'].values\n",
    "\n",
    "    for embedding in embeddings:\n",
    "        X = get_embeddings(corpus, embedding)\n",
    "\n",
    "        for classifier in get_classifiers(classifiers, multilabel=True):\n",
    "            labels = set()\n",
    "            y_pred_all = None\n",
    "            y_test_all = None\n",
    "            for fold in range(1, 6):\n",
    "                X_train = X[df['Split'] != fold]\n",
    "                X_test = X[df['Split'] == fold]\n",
    "\n",
    "                y_train = df[df['Split'] != fold][attribute]\n",
    "                y_test = df[df['Split'] == fold][attribute]\n",
    "\n",
    "                ml = MultiLabelBinarizer()\n",
    "                y_train = ml.fit_transform(y_train)\n",
    "                y_test = ml.fit_transform(y_test)\n",
    "                labels = labels.union(ml.classes_)\n",
    "\n",
    "                if classifier == 'random':\n",
    "                    y_pred = [random.sample(labels, random.randint(1, len(labels))) for _ in range(len(X_test))]\n",
    "                    y_pred = ml.transform(y_pred)\n",
    "                elif classifier == 'majority':\n",
    "                    mask = []\n",
    "                    for l in sorted(labels):\n",
    "                        count = 0\n",
    "                        for element in list(ml.inverse_transform(y_train)):\n",
    "                            if l in element:\n",
    "                                count += 1\n",
    "                        if count > len(list(y_train))/2:\n",
    "                            mask.append(True)\n",
    "                        else:\n",
    "                            mask.append(False)\n",
    "                    sample = [1 if el else 0 for el in mask]\n",
    "                    y_pred = [sample for _ in range(len(X_test))]\n",
    "                else:\n",
    "                    classifier.fit(X_train, y_train)\n",
    "                    y_pred = classifier.predict(X_test)\n",
    "\n",
    "                y_pred_all = y_pred if y_pred_all is None else np.concatenate([y_pred_all, y_pred])\n",
    "                y_test_all = y_test if y_test_all is None else np.concatenate([y_test_all, y_test])\n",
    "\n",
    "            labels = sorted(labels)\n",
    "\n",
    "            report = classification_report(y_test_all, y_pred_all, target_names=labels)\n",
    "            print(\"EMBEDDING:\" + embedding + \"      CLASSIFIER:\" + str(classifier.estimator.__class__).split('.')[-1].split(\"'\")[0])\n",
    "            print(report)\n",
    "            print(\"=\"*40)\n",
    "\n",
    "def training_dynamics(prob_y):\n",
    "    confidence = sum(prob_y)/len(prob_y)\n",
    "    variability = math.sqrt((sum([(i-confidence)**2 for i in prob_y]))/len(prob_y))\n",
    "    return confidence,variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5zbi2WIA99v",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oTQsIe1AQ60Z",
    "outputId": "96272277-dbd2-4d83-a88e-7ccbda16b7eb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type\n",
      "[L]       1598\n",
      "[F]       1469\n",
      "[F, L]     107\n",
      "Name: count, dtype: int64 3174\n",
      "EMBEDDING:tfidf      CLASSIFIER:LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.92      0.85      0.88      1576\n",
      "           L       0.87      0.92      0.89      1705\n",
      "\n",
      "   micro avg       0.89      0.88      0.89      3281\n",
      "   macro avg       0.89      0.88      0.89      3281\n",
      "weighted avg       0.89      0.88      0.89      3281\n",
      " samples avg       0.89      0.90      0.89      3281\n",
      "\n",
      "========================================\n",
      "EMBEDDING:tfidf      CLASSIFIER:RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.90      0.91      0.90      1576\n",
      "           L       0.91      0.89      0.90      1705\n",
      "\n",
      "   micro avg       0.91      0.90      0.90      3281\n",
      "   macro avg       0.91      0.90      0.90      3281\n",
      "weighted avg       0.91      0.90      0.90      3281\n",
      " samples avg       0.91      0.91      0.91      3281\n",
      "\n",
      "========================================\n",
      "EMBEDDING:tfidf      CLASSIFIER:GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.85      0.74      0.79      1576\n",
      "           L       0.77      0.87      0.81      1705\n",
      "\n",
      "   micro avg       0.80      0.81      0.81      3281\n",
      "   macro avg       0.81      0.81      0.80      3281\n",
      "weighted avg       0.81      0.81      0.81      3281\n",
      " samples avg       0.81      0.82      0.81      3281\n",
      "\n",
      "========================================\n",
      "EMBEDDING:tfidf      CLASSIFIER:KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.91      0.72      0.81      1576\n",
      "           L       0.78      0.92      0.84      1705\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      3281\n",
      "   macro avg       0.85      0.82      0.83      3281\n",
      "weighted avg       0.84      0.83      0.83      3281\n",
      " samples avg       0.84      0.84      0.83      3281\n",
      "\n",
      "========================================\n",
      "EMBEDDING:tfidf      CLASSIFIER:SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.91      0.97      0.94      1576\n",
      "           L       0.90      0.93      0.92      1705\n",
      "\n",
      "   micro avg       0.91      0.95      0.93      3281\n",
      "   macro avg       0.91      0.95      0.93      3281\n",
      "weighted avg       0.91      0.95      0.93      3281\n",
      " samples avg       0.94      0.96      0.94      3281\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.83      0.80      0.81      1576\n",
      "           L       0.81      0.86      0.83      1705\n",
      "\n",
      "   micro avg       0.82      0.83      0.82      3281\n",
      "   macro avg       0.82      0.83      0.82      3281\n",
      "weighted avg       0.82      0.83      0.82      3281\n",
      " samples avg       0.81      0.84      0.82      3281\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.83      0.80      0.81      1576\n",
      "           L       0.81      0.84      0.82      1705\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      3281\n",
      "   macro avg       0.82      0.82      0.82      3281\n",
      "weighted avg       0.82      0.82      0.82      3281\n",
      " samples avg       0.81      0.83      0.81      3281\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.74      0.71      0.72      1576\n",
      "           L       0.74      0.75      0.75      1705\n",
      "\n",
      "   micro avg       0.74      0.73      0.73      3281\n",
      "   macro avg       0.74      0.73      0.73      3281\n",
      "weighted avg       0.74      0.73      0.73      3281\n",
      " samples avg       0.74      0.73      0.73      3281\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.83      0.66      0.74      1576\n",
      "           L       0.72      0.87      0.79      1705\n",
      "\n",
      "   micro avg       0.76      0.77      0.76      3281\n",
      "   macro avg       0.77      0.77      0.76      3281\n",
      "weighted avg       0.77      0.77      0.76      3281\n",
      " samples avg       0.77      0.78      0.77      3281\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.87      0.81      0.84      1576\n",
      "           L       0.83      0.88      0.86      1705\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      3281\n",
      "   macro avg       0.85      0.85      0.85      3281\n",
      "weighted avg       0.85      0.85      0.85      3281\n",
      " samples avg       0.86      0.86      0.85      3281\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\utente/.cache\\torch\\sentence_transformers\\nlpaueb_legal-bert-small-uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\utente/.cache\\torch\\sentence_transformers\\nlpaueb_legal-bert-small-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDING:legalbert      CLASSIFIER:LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.87      0.85      0.86      1576\n",
      "           L       0.84      0.87      0.86      1705\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      3281\n",
      "   macro avg       0.86      0.86      0.86      3281\n",
      "weighted avg       0.86      0.86      0.86      3281\n",
      " samples avg       0.85      0.87      0.85      3281\n",
      "\n",
      "========================================\n",
      "EMBEDDING:legalbert      CLASSIFIER:RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.84      0.86      0.85      1576\n",
      "           L       0.86      0.86      0.86      1705\n",
      "\n",
      "   micro avg       0.85      0.86      0.86      3281\n",
      "   macro avg       0.85      0.86      0.86      3281\n",
      "weighted avg       0.85      0.86      0.86      3281\n",
      " samples avg       0.85      0.87      0.85      3281\n",
      "\n",
      "========================================\n",
      "EMBEDDING:legalbert      CLASSIFIER:GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.75      0.74      0.75      1576\n",
      "           L       0.75      0.76      0.76      1705\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      3281\n",
      "   macro avg       0.75      0.75      0.75      3281\n",
      "weighted avg       0.75      0.75      0.75      3281\n",
      " samples avg       0.76      0.76      0.75      3281\n",
      "\n",
      "========================================\n",
      "EMBEDDING:legalbert      CLASSIFIER:KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.91      0.75      0.82      1576\n",
      "           L       0.78      0.93      0.85      1705\n",
      "\n",
      "   micro avg       0.83      0.84      0.84      3281\n",
      "   macro avg       0.84      0.84      0.84      3281\n",
      "weighted avg       0.84      0.84      0.84      3281\n",
      " samples avg       0.84      0.85      0.84      3281\n",
      "\n",
      "========================================\n",
      "EMBEDDING:legalbert      CLASSIFIER:SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.90      0.85      0.88      1576\n",
      "           L       0.88      0.91      0.89      1705\n",
      "\n",
      "   micro avg       0.89      0.88      0.88      3281\n",
      "   macro avg       0.89      0.88      0.88      3281\n",
      "weighted avg       0.89      0.88      0.88      3281\n",
      " samples avg       0.89      0.89      0.89      3281\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "df_sentences = pd.read_pickle(\"./updated_tc_df.pkl\")\n",
    "#df_annotations = pd.read_pickle(\"./updatedsent_df.pkl\")\n",
    "\n",
    "# list of classifiers and embeddings to try\n",
    "classifiers = ['linearsvc', 'randomforest', 'gaussiannb', 'kneighbors', 'svc']\n",
    "# classifiers = ['random', 'majority']\n",
    "embeddings = ['tfidf', 'sbert', 'legalbert']\n",
    "\n",
    "# argument detection\n",
    "#argumentmining.argument_classification(df_sentences, classifiers, embeddings)\n",
    "\n",
    "# type classification\n",
    "attribute_classification(df_sentences, classifiers, embeddings, 'Type')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3WzSerXBBj7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Q-4cL-YSAolD",
    "outputId": "bdc20a3e-166d-4a78-deb9-19d66829785c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheme\n",
      "[Prec]                 576\n",
      "[Itpr]                 298\n",
      "[Prec, Rule]           225\n",
      "[Rule]                 162\n",
      "[Itpr, Rule]           127\n",
      "[Class]                 53\n",
      "[Itpr, Prec]            50\n",
      "[Itpr, Prec, Rule]      43\n",
      "[Aut]                   37\n",
      "[Class, Prec]           28\n",
      "[Class, Prec, Rule]     15\n",
      "[Aut, Itpr, Rule]       12\n",
      "[Prec, Princ]           10\n",
      "[Aut, Itpr]             10\n",
      "[Class, Rule]            9\n",
      "[Princ, Rule]            7\n",
      "[Princ]                  5\n",
      "[Aut, Prec]              4\n",
      "[Itpr, Princ]            2\n",
      "[Aut, Class, Rule]       2\n",
      "[Aut, Rule]              2\n",
      "[Class, Itpr]            2\n",
      "[Aut, Prec, Princ]       2\n",
      "[Aut, Itpr, Prec]        2\n",
      "[Aut, Prec, Rule]        1\n",
      "Name: count, dtype: int64 1684\n",
      "EMBEDDING:tfidf      CLASSIFIER:LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       1.00      0.83      0.91        72\n",
      "       Class       0.98      0.78      0.87       109\n",
      "        Itpr       0.84      0.77      0.81       546\n",
      "        Prec       0.95      0.95      0.95       956\n",
      "       Princ       0.91      0.38      0.54        26\n",
      "        Rule       0.97      0.90      0.93       605\n",
      "\n",
      "   micro avg       0.93      0.88      0.90      2314\n",
      "   macro avg       0.94      0.77      0.83      2314\n",
      "weighted avg       0.93      0.88      0.90      2314\n",
      " samples avg       0.90      0.89      0.89      2314\n",
      "\n",
      "========================================\n",
      "EMBEDDING:tfidf      CLASSIFIER:RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       1.00      0.75      0.86        72\n",
      "       Class       0.97      0.56      0.71       109\n",
      "        Itpr       0.89      0.57      0.70       546\n",
      "        Prec       0.96      0.94      0.95       956\n",
      "       Princ       0.86      0.23      0.36        26\n",
      "        Rule       0.95      0.94      0.95       605\n",
      "\n",
      "   micro avg       0.95      0.82      0.88      2314\n",
      "   macro avg       0.94      0.67      0.75      2314\n",
      "weighted avg       0.94      0.82      0.87      2314\n",
      " samples avg       0.88      0.84      0.85      2314\n",
      "\n",
      "========================================\n",
      "EMBEDDING:tfidf      CLASSIFIER:GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       0.42      0.18      0.25        72\n",
      "       Class       0.95      0.64      0.77       109\n",
      "        Itpr       0.76      0.73      0.74       546\n",
      "        Prec       0.84      0.91      0.88       956\n",
      "       Princ       0.67      0.31      0.42        26\n",
      "        Rule       0.70      0.83      0.76       605\n",
      "\n",
      "   micro avg       0.78      0.80      0.79      2314\n",
      "   macro avg       0.72      0.60      0.64      2314\n",
      "weighted avg       0.78      0.80      0.78      2314\n",
      " samples avg       0.79      0.81      0.78      2314\n",
      "\n",
      "========================================\n",
      "EMBEDDING:tfidf      CLASSIFIER:KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       0.98      0.56      0.71        72\n",
      "       Class       0.69      0.77      0.73       109\n",
      "        Itpr       0.73      0.52      0.61       546\n",
      "        Prec       0.83      0.86      0.85       956\n",
      "       Princ       0.75      0.12      0.20        26\n",
      "        Rule       0.81      0.80      0.80       605\n",
      "\n",
      "   micro avg       0.80      0.74      0.77      2314\n",
      "   macro avg       0.80      0.60      0.65      2314\n",
      "weighted avg       0.80      0.74      0.76      2314\n",
      " samples avg       0.78      0.76      0.76      2314\n",
      "\n",
      "========================================\n",
      "EMBEDDING:tfidf      CLASSIFIER:SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       0.00      0.00      0.00        72\n",
      "       Class       0.96      0.47      0.63       109\n",
      "        Itpr       0.89      0.23      0.36       546\n",
      "        Prec       0.80      0.97      0.88       956\n",
      "       Princ       0.80      0.15      0.26        26\n",
      "        Rule       0.97      0.58      0.73       605\n",
      "\n",
      "   micro avg       0.85      0.63      0.72      2314\n",
      "   macro avg       0.74      0.40      0.48      2314\n",
      "weighted avg       0.85      0.63      0.67      2314\n",
      " samples avg       0.72      0.65      0.67      2314\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       0.93      0.72      0.81        72\n",
      "       Class       0.82      0.75      0.78       109\n",
      "        Itpr       0.63      0.62      0.62       546\n",
      "        Prec       0.88      0.91      0.89       956\n",
      "       Princ       0.80      0.46      0.59        26\n",
      "        Rule       0.82      0.80      0.81       605\n",
      "\n",
      "   micro avg       0.81      0.79      0.80      2314\n",
      "   macro avg       0.81      0.71      0.75      2314\n",
      "weighted avg       0.81      0.79      0.80      2314\n",
      " samples avg       0.79      0.81      0.78      2314\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       0.00      0.00      0.00        72\n",
      "       Class       0.95      0.37      0.53       109\n",
      "        Itpr       0.79      0.50      0.61       546\n",
      "        Prec       0.85      0.84      0.85       956\n",
      "       Princ       0.67      0.08      0.14        26\n",
      "        Rule       0.89      0.50      0.64       605\n",
      "\n",
      "   micro avg       0.85      0.61      0.71      2314\n",
      "   macro avg       0.69      0.38      0.46      2314\n",
      "weighted avg       0.82      0.61      0.69      2314\n",
      " samples avg       0.74      0.66      0.68      2314\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       0.22      0.58      0.32        72\n",
      "       Class       0.32      0.60      0.41       109\n",
      "        Itpr       0.53      0.69      0.60       546\n",
      "        Prec       0.83      0.81      0.82       956\n",
      "       Princ       0.19      0.31      0.23        26\n",
      "        Rule       0.54      0.71      0.61       605\n",
      "\n",
      "   micro avg       0.59      0.73      0.65      2314\n",
      "   macro avg       0.44      0.62      0.50      2314\n",
      "weighted avg       0.63      0.73      0.67      2314\n",
      " samples avg       0.62      0.76      0.65      2314\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       0.00      0.00      0.00        72\n",
      "       Class       0.76      0.61      0.68       109\n",
      "        Itpr       0.74      0.44      0.55       546\n",
      "        Prec       0.76      0.91      0.83       956\n",
      "       Princ       1.00      0.04      0.07        26\n",
      "        Rule       0.67      0.69      0.68       605\n",
      "\n",
      "   micro avg       0.73      0.69      0.71      2314\n",
      "   macro avg       0.65      0.45      0.47      2314\n",
      "weighted avg       0.71      0.69      0.68      2314\n",
      " samples avg       0.73      0.71      0.70      2314\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       1.00      0.11      0.20        72\n",
      "       Class       0.96      0.49      0.65       109\n",
      "        Itpr       0.79      0.53      0.64       546\n",
      "        Prec       0.91      0.88      0.89       956\n",
      "       Princ       0.00      0.00      0.00        26\n",
      "        Rule       0.87      0.71      0.78       605\n",
      "\n",
      "   micro avg       0.88      0.70      0.78      2314\n",
      "   macro avg       0.76      0.45      0.53      2314\n",
      "weighted avg       0.87      0.70      0.76      2314\n",
      " samples avg       0.81      0.74      0.75      2314\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\utente/.cache\\torch\\sentence_transformers\\nlpaueb_legal-bert-small-uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\utente/.cache\\torch\\sentence_transformers\\nlpaueb_legal-bert-small-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDING:legalbert      CLASSIFIER:LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       0.94      0.85      0.89        72\n",
      "       Class       0.80      0.76      0.78       109\n",
      "        Itpr       0.67      0.62      0.64       546\n",
      "        Prec       0.91      0.92      0.91       956\n",
      "       Princ       0.65      0.58      0.61        26\n",
      "        Rule       0.86      0.82      0.84       605\n",
      "\n",
      "   micro avg       0.83      0.81      0.82      2314\n",
      "   macro avg       0.80      0.76      0.78      2314\n",
      "weighted avg       0.83      0.81      0.82      2314\n",
      " samples avg       0.81      0.82      0.80      2314\n",
      "\n",
      "========================================\n",
      "EMBEDDING:legalbert      CLASSIFIER:RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       0.00      0.00      0.00        72\n",
      "       Class       0.95      0.37      0.53       109\n",
      "        Itpr       0.79      0.57      0.66       546\n",
      "        Prec       0.95      0.85      0.89       956\n",
      "       Princ       0.67      0.08      0.14        26\n",
      "        Rule       0.94      0.59      0.72       605\n",
      "\n",
      "   micro avg       0.91      0.66      0.76      2314\n",
      "   macro avg       0.72      0.41      0.49      2314\n",
      "weighted avg       0.87      0.66      0.74      2314\n",
      " samples avg       0.80      0.70      0.73      2314\n",
      "\n",
      "========================================\n",
      "EMBEDDING:legalbert      CLASSIFIER:GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       0.44      0.81      0.57        72\n",
      "       Class       0.30      0.50      0.38       109\n",
      "        Itpr       0.53      0.78      0.63       546\n",
      "        Prec       0.92      0.81      0.86       956\n",
      "       Princ       0.40      0.46      0.43        26\n",
      "        Rule       0.73      0.76      0.74       605\n",
      "\n",
      "   micro avg       0.68      0.77      0.72      2314\n",
      "   macro avg       0.55      0.69      0.60      2314\n",
      "weighted avg       0.73      0.77      0.74      2314\n",
      " samples avg       0.73      0.80      0.73      2314\n",
      "\n",
      "========================================\n",
      "EMBEDDING:legalbert      CLASSIFIER:KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       0.81      0.18      0.30        72\n",
      "       Class       0.84      0.58      0.68       109\n",
      "        Itpr       0.79      0.42      0.55       546\n",
      "        Prec       0.75      0.97      0.84       956\n",
      "       Princ       1.00      0.12      0.21        26\n",
      "        Rule       0.80      0.79      0.80       605\n",
      "\n",
      "   micro avg       0.77      0.74      0.76      2314\n",
      "   macro avg       0.83      0.51      0.56      2314\n",
      "weighted avg       0.78      0.74      0.73      2314\n",
      " samples avg       0.78      0.77      0.75      2314\n",
      "\n",
      "========================================\n",
      "EMBEDDING:legalbert      CLASSIFIER:SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Aut       1.00      0.38      0.55        72\n",
      "       Class       0.95      0.38      0.54       109\n",
      "        Itpr       0.77      0.65      0.70       546\n",
      "        Prec       0.94      0.90      0.92       956\n",
      "       Princ       0.00      0.00      0.00        26\n",
      "        Rule       0.93      0.73      0.82       605\n",
      "\n",
      "   micro avg       0.90      0.75      0.82      2314\n",
      "   macro avg       0.77      0.51      0.59      2314\n",
      "weighted avg       0.89      0.75      0.80      2314\n",
      " samples avg       0.87      0.79      0.81      2314\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# scheme classification\n",
    "attribute_classification(df_sentences, classifiers, embeddings, 'Scheme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BRd3DWHwAolF",
    "outputId": "1ccf0e35-3b80-4461-aa3c-49335ea355d3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3334 sentences, but 160 cannot be used.\n"
     ]
    }
   ],
   "source": [
    "count_nan = df_sentences['Type'].isna().sum()\n",
    "count_L = df_sentences[df_sentences['Type'] == 'L'].shape[0]\n",
    "count_F = df_sentences[df_sentences['Type'] == 'F'].shape[0]\n",
    "print(f'There are {len(df_sentences)} sentences, but {count_nan} cannot be used.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jdLmiz4BINq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lrRJ41jfAolF",
    "outputId": "d6d304f5-fc9f-450f-f2db-d8e817c6927d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDING:tfidf      CLASSIFIER:LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.94      0.92      0.93       480\n",
      "        prem       0.99      0.99      0.99      3174\n",
      "\n",
      "    accuracy                           0.98      3654\n",
      "   macro avg       0.96      0.96      0.96      3654\n",
      "weighted avg       0.98      0.98      0.98      3654\n",
      "\n",
      "========================================\n",
      "EMBEDDING:tfidf      CLASSIFIER:RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.93      0.95      0.94       480\n",
      "        prem       0.99      0.99      0.99      3174\n",
      "\n",
      "    accuracy                           0.98      3654\n",
      "   macro avg       0.96      0.97      0.96      3654\n",
      "weighted avg       0.98      0.98      0.98      3654\n",
      "\n",
      "========================================\n",
      "EMBEDDING:tfidf      CLASSIFIER:GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.91      0.92      0.91       480\n",
      "        prem       0.99      0.99      0.99      3174\n",
      "\n",
      "    accuracy                           0.98      3654\n",
      "   macro avg       0.95      0.95      0.95      3654\n",
      "weighted avg       0.98      0.98      0.98      3654\n",
      "\n",
      "========================================\n",
      "EMBEDDING:tfidf      CLASSIFIER:KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.73      0.96      0.83       480\n",
      "        prem       0.99      0.95      0.97      3174\n",
      "\n",
      "    accuracy                           0.95      3654\n",
      "   macro avg       0.86      0.95      0.90      3654\n",
      "weighted avg       0.96      0.95      0.95      3654\n",
      "\n",
      "========================================\n",
      "EMBEDDING:tfidf      CLASSIFIER:SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.96      0.86      0.91       480\n",
      "        prem       0.98      0.99      0.99      3174\n",
      "\n",
      "    accuracy                           0.98      3654\n",
      "   macro avg       0.97      0.93      0.95      3654\n",
      "weighted avg       0.98      0.98      0.98      3654\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.90      0.91      0.90       480\n",
      "        prem       0.99      0.98      0.99      3174\n",
      "\n",
      "    accuracy                           0.97      3654\n",
      "   macro avg       0.94      0.95      0.94      3654\n",
      "weighted avg       0.97      0.97      0.97      3654\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.93      0.87      0.90       480\n",
      "        prem       0.98      0.99      0.99      3174\n",
      "\n",
      "    accuracy                           0.97      3654\n",
      "   macro avg       0.96      0.93      0.94      3654\n",
      "weighted avg       0.97      0.97      0.97      3654\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.70      0.84      0.76       480\n",
      "        prem       0.97      0.95      0.96      3174\n",
      "\n",
      "    accuracy                           0.93      3654\n",
      "   macro avg       0.84      0.89      0.86      3654\n",
      "weighted avg       0.94      0.93      0.93      3654\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.84      0.90      0.87       480\n",
      "        prem       0.98      0.97      0.98      3174\n",
      "\n",
      "    accuracy                           0.96      3654\n",
      "   macro avg       0.91      0.94      0.92      3654\n",
      "weighted avg       0.97      0.96      0.96      3654\n",
      "\n",
      "========================================\n",
      "EMBEDDING:sbert      CLASSIFIER:SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.90      0.90      0.90       480\n",
      "        prem       0.98      0.99      0.98      3174\n",
      "\n",
      "    accuracy                           0.97      3654\n",
      "   macro avg       0.94      0.94      0.94      3654\n",
      "weighted avg       0.97      0.97      0.97      3654\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\utente/.cache\\torch\\sentence_transformers\\nlpaueb_legal-bert-small-uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\utente/.cache\\torch\\sentence_transformers\\nlpaueb_legal-bert-small-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDING:legalbert      CLASSIFIER:LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.87      0.88      0.88       480\n",
      "        prem       0.98      0.98      0.98      3174\n",
      "\n",
      "    accuracy                           0.97      3654\n",
      "   macro avg       0.93      0.93      0.93      3654\n",
      "weighted avg       0.97      0.97      0.97      3654\n",
      "\n",
      "========================================\n",
      "EMBEDDING:legalbert      CLASSIFIER:RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.93      0.89      0.91       480\n",
      "        prem       0.98      0.99      0.99      3174\n",
      "\n",
      "    accuracy                           0.98      3654\n",
      "   macro avg       0.96      0.94      0.95      3654\n",
      "weighted avg       0.98      0.98      0.98      3654\n",
      "\n",
      "========================================\n",
      "EMBEDDING:legalbert      CLASSIFIER:GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.77      0.88      0.82       480\n",
      "        prem       0.98      0.96      0.97      3174\n",
      "\n",
      "    accuracy                           0.95      3654\n",
      "   macro avg       0.87      0.92      0.89      3654\n",
      "weighted avg       0.95      0.95      0.95      3654\n",
      "\n",
      "========================================\n",
      "EMBEDDING:legalbert      CLASSIFIER:KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.86      0.90      0.88       480\n",
      "        prem       0.98      0.98      0.98      3174\n",
      "\n",
      "    accuracy                           0.97      3654\n",
      "   macro avg       0.92      0.94      0.93      3654\n",
      "weighted avg       0.97      0.97      0.97      3654\n",
      "\n",
      "========================================\n",
      "EMBEDDING:legalbert      CLASSIFIER:SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        conc       0.92      0.90      0.91       480\n",
      "        prem       0.98      0.99      0.99      3174\n",
      "\n",
      "    accuracy                           0.98      3654\n",
      "   macro avg       0.95      0.94      0.95      3654\n",
      "weighted avg       0.98      0.98      0.98      3654\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "df_sentences_ac = pd.read_pickle(\"./updated_df_ac.pkl\")\n",
    "\n",
    "# list of classifiers and embeddings to try\n",
    "classifiers = ['linearsvc', 'randomforest', 'gaussiannb', 'kneighbors', 'svc']\n",
    "# classifiers = ['random', 'majority']\n",
    "embeddings = ['tfidf', 'sbert', 'legalbert']\n",
    "\n",
    "# argument detection\n",
    "argument_classification(df_sentences_ac, classifiers, embeddings)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
